{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.31.5 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy nltk scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"creditcard.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values in each column : \n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check missing value\n",
    "\n",
    "missing_values = data.isnull().sum()\n",
    "print (\"missing values in each column : \")\n",
    "print(missing_values)\n",
    "\n",
    "# drop any missing values\n",
    "data.dropna(inplace = True)\n",
    "\n",
    "# Basic NLP preprocessing\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    words = [word for word in words if word.isalpha() and word not in stopwords.words('english')]\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocomplete suggestions for 'V1': []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(r'creditcard.csv')\n",
    "\n",
    "data['V1'] = data['V1'].astype(str).fillna('')\n",
    "\n",
    "\n",
    "#create autocomplete function\n",
    "\n",
    "class Autocomplete:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.vectorizer.fit(data)\n",
    "    \n",
    "    def predict(self, prefix):\n",
    "        words = [word for word in self.data if word.startswith(prefix)]\n",
    "        return words\n",
    "\n",
    "autocomplete_model = Autocomplete(data['V1'].tolist())\n",
    "\n",
    "prefix = \"V1\"\n",
    "predictions = autocomplete_model.predict(prefix)\n",
    "print(f\"Autocomplete suggestions for '{prefix}': {predictions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocomplete suggestions for 'exam': []\n",
      "Autocomplete suggestions for 'cre': []\n",
      "Autocomplete suggestions for 'aut': []\n",
      "Autocomplete suggestions for 'credit': []\n",
      "Autocomplete suggestions for 'sample': []\n"
     ]
    }
   ],
   "source": [
    "test_prefixes = [\"exam\", \"cre\", \"aut\", \"credit\", \"sample\"]  # Add more prefixes as needed\n",
    "for prefix in test_prefixes:\n",
    "    predictions = autocomplete_model.predict(prefix)\n",
    "    print(f\"Autocomplete suggestions for '{prefix}': {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested correction for 'exampel': []\n"
     ]
    }
   ],
   "source": [
    "from difflib import get_close_matches\n",
    "\n",
    "# Function to perform basic autocorrection\n",
    "def autocorrect(word, options):\n",
    "    return get_close_matches(word, options, n=1, cutoff=0.8)\n",
    "\n",
    "\n",
    "input_word = \"exampel\"  \n",
    "suggestion = autocorrect(input_word, data['V1'].tolist())\n",
    "print(f\"Suggested correction for '{input_word}': {suggestion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(actual, predicted):\n",
    "    print(\"Model Accuracy:\", accuracy_score(actual, predicted))\n",
    "    print(\"Detailed Classification Report:\\n\", classification_report(actual, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data['Amount'], bins = 30, kde = True)\n",
    "plt.title('Distribution of amount')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feedback received : True\n"
     ]
    }
   ],
   "source": [
    "def gather_feedback(predictions, user_input):\n",
    "    \n",
    "    feedback = input(f\"Did the suggestions{predictions} help? (yes/no): \")\n",
    "    return feedback.lower() == \"yes\"\n",
    "\n",
    "user_input = \"exam\"\n",
    "feedback_received = gather_feedback(predictions, user_input)\n",
    "print(f\" Feedback received : {feedback_received}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      " 0     example\n",
      "1     examine\n",
      "2        exam\n",
      "3    exercise\n",
      "4       extra\n",
      "5        None\n",
      "6            \n",
      "7            \n",
      "Name: V1, dtype: object\n",
      "\n",
      "Cleaned data:\n",
      " 0     example\n",
      "1     examine\n",
      "2        exam\n",
      "3    exercise\n",
      "4       extra\n",
      "Name: V1, dtype: object\n",
      "Error: empty vocabulary; perhaps the documents only contain stop words\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample DataFrame (Replace with your actual data)\n",
    "data = pd.DataFrame({'V1': ['example', 'examine', 'exam', 'exercise', 'extra', None, '   ','']})\n",
    "\n",
    "# Inspect the original data\n",
    "print(\"Original data:\\n\", data['V1'])\n",
    "\n",
    "# Preprocess the data\n",
    "data = data.dropna(subset=['V1'])  # Remove rows with NaNs in V1\n",
    "data = data[data['V1'].str.strip() != '']  # Remove empty strings\n",
    "\n",
    "# Check the cleaned data\n",
    "print(\"\\nCleaned data:\\n\", data['V1'])\n",
    "\n",
    "class NGramAutocomplete:\n",
    "    def __init__(self, data, n=2):\n",
    "        self.data = data\n",
    "        self.n = n\n",
    "\n",
    "        # Ensure the data is a list of strings\n",
    "        if not all(isinstance(text, str) for text in self.data):\n",
    "            raise ValueError(\"All items in the data must be strings.\")\n",
    "        self.vectorizer = CountVectorizer(ngram_range=(n, n), lowercase=True)\n",
    "        self.vectorizer.fit(data)\n",
    "\n",
    "    def predict(self, prefix):\n",
    "        matches = [text for text in self.data if text.startswith(prefix)]\n",
    "        return matches\n",
    "\n",
    "try:\n",
    "    ngram_autocomplete_model = NGramAutocomplete(data['V1'].tolist(), n=3)\n",
    "    prefix = \"exam\"\n",
    "    predictions = ngram_autocomplete_model.predict(prefix)\n",
    "    print(f\"N-gram autocomplete suggestions for '{prefix}' : {predictions}\")\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
      "gradio 4.31.5 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n",
      "gradio 4.31.5 requires numpy~=1.0, but you have numpy 2.2.5 which is incompatible.\n",
      "langchain 0.1.16 requires numpy<2,>=1, but you have numpy 2.2.5 which is incompatible.\n",
      "langchain-community 0.0.34 requires numpy<2,>=1, but you have numpy 2.2.5 which is incompatible.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
      "pandas 2.2.1 requires numpy<2,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.2.5 which is incompatible.\n",
      "streamlit 1.33.0 requires numpy<2,>=1.19.3, but you have numpy 2.2.5 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.2.5 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.5-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.5-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.5\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.3)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.31.5 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall numpy gensim -y\n",
    "# pip install numpy gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      float64\n",
      "V1        float64\n",
      "V2        float64\n",
      "V3        float64\n",
      "V4        float64\n",
      "V5        float64\n",
      "V6        float64\n",
      "V7        float64\n",
      "V8        float64\n",
      "V9        float64\n",
      "V10       float64\n",
      "V11       float64\n",
      "V12       float64\n",
      "V13       float64\n",
      "V14       float64\n",
      "V15       float64\n",
      "V16       float64\n",
      "V17       float64\n",
      "V18       float64\n",
      "V19       float64\n",
      "V20       float64\n",
      "V21       float64\n",
      "V22       float64\n",
      "V23       float64\n",
      "V24       float64\n",
      "V25       float64\n",
      "V26       float64\n",
      "V27       float64\n",
      "V28       float64\n",
      "Amount    float64\n",
      "Class       int64\n",
      "dtype: object\n",
      "Contextual suggestions for 'exampel': []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Sample DataFrame (Replace with your actual data)\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Check the data types\n",
    "print(data.dtypes)\n",
    "\n",
    "# Handle missing values by dropping or filling\n",
    "data = data.dropna(subset=['V1'])  # Option 1: drop rows with NaN in 'V1'\n",
    "# or\n",
    "# data['V1'] = data['V1'].fillna('') # Option 2: fill NaN with an empty string\n",
    "\n",
    "# Convert the V1 column to strings\n",
    "data['V1'] = data['V1'].astype(str)\n",
    "\n",
    "# Create sentences for Word2Vec\n",
    "sentences = [text.lower().split() for text in data['V1'].tolist()]\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def contextual_autocorrect(word):\n",
    "    if word in model.wv:\n",
    "        similar_words = model.wv.most_similar(word, topn=5)\n",
    "        return [w for w, _ in similar_words]\n",
    "    return []\n",
    "\n",
    "# Example usage\n",
    "input_word = \"exampel\"\n",
    "suggestion = contextual_autocorrect(input_word)\n",
    "print(f\"Contextual suggestions for '{input_word}': {suggestion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextual suggestions for 'exampel': []\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Assuming you have a list of sentences or text corpus\n",
    "sentences = [text.lower().split() for text in data['V1'].tolist()]\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def contextual_autocorrect(word):\n",
    "    if word in model.wv:\n",
    "        similar_words = model.wv.most_similar(word, topn=5)\n",
    "        return [w for w, _ in similar_words]\n",
    "    return []\n",
    "\n",
    "# Example usage\n",
    "word_to_correct = \"exampel\"\n",
    "corrected_words = contextual_autocorrect(word_to_correct)\n",
    "print(f\"Contextual suggestions for '{word_to_correct}': {corrected_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.33.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.1)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (16.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.21.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# StreamLit App\n",
    "st.title('Autocomplete and Autocorrect Tool')\n",
    "\n",
    "user_input = st.text_input(\"Enter text for autocomplete:\")\n",
    "if user_input:\n",
    "    autocomplete_suggestions = autocomplete_model.predict(user_input)\n",
    "    st.write(\"Autocomplete Suggestions:\", autocomplete_suggestions)\n",
    "\n",
    "user_word = st.text_input(\"Enter a word for autocorrect:\")\n",
    "if user_word:\n",
    "    corrected_word = autocorrect(user_word, data['V1'].tolist())\n",
    "    st.write(\"Suggested Correction:\", corrected_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Example dataset for demonstration\n",
    "data = [\"apple\", \"banana\", \"grape\", \"orange\", \"strawberry\"]\n",
    "\n",
    "# Define and fit a simple model\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data)\n",
    "y = [\"fruit\"] * len(data)  # Dummy target\n",
    "\n",
    "autocomplete_model = MultinomialNB()\n",
    "autocomplete_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocomplete Result: ['apple']\n",
      "Autocomplete time: 0.0000seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Example dataset for demonstration\n",
    "data = [\"apple\", \"banana\", \"grape\", \"orange\", \"strawberry\"]\n",
    "\n",
    "# Define and fit a simple model\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data)\n",
    "y = [\"fruit\"] * len(data)  # Dummy target\n",
    "\n",
    "autocomplete_model = MultinomialNB()\n",
    "autocomplete_model.fit(X, y)\n",
    "\n",
    "def benchmark_function(func, *args):\n",
    "    start_time = time.time()\n",
    "    result = func(*args)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    return result, execution_time\n",
    "\n",
    "# Example prefix to predict (You would have a proper prediction function)\n",
    "prefix = \"a\" # Example input for testing\n",
    "\n",
    "# Example prediction function (make sure this matches your actual model's predict method)\n",
    "def predict(prefix):\n",
    "    # In a real case, you would implement the logic to return predictions based on the prefix\n",
    "    # Here, we return a dummy response for demonstration\n",
    "    return [word for word in data if word.startswith(prefix)]\n",
    "\n",
    "autocomplete_result, autocomplete_time = benchmark_function(predict,prefix)\n",
    "print(f\"Autocomplete Result: {autocomplete_result}\")\n",
    "print(f\"Autocomplete time: {autocomplete_time:.4f}seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No autocomplete suggestions found for the prefix 'exam'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('creditcard.csv')  # Adjust the path as needed\n",
    "\n",
    "# Assuming 'V1' is the column that contains text data for autocomplete\n",
    "# Filter only string entries and drop NaN values\n",
    "data['V1'] = data['V1'].astype(str)  # Convert all entries to string\n",
    "sentences = [text.lower().split() for text in data['V1'] if isinstance(text, str) and text.strip()] # Only keep non-empty strings\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to predict autocomplete suggestions based on prefix\n",
    "def predict(prefix):\n",
    "    try:\n",
    "        similar_words = model.wv.most_similar(prefix, topn=5) # Get top 5 similar words\n",
    "        return [word for word, _ in similar_words]\n",
    "    except KeyError:\n",
    "        return [] # Return empty list if prefix not in vocabulary\n",
    "\n",
    "# Example prefix for predictions\n",
    "prefix = \"exam\" # Change this to the prefix you're interested in\n",
    "predictions = predict(prefix)\n",
    "\n",
    "if predictions: # Check if there are predictions to display\n",
    "    suggestions_df = pd.DataFrame({'Suggestions': predictions})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(y='Suggestions', data=suggestions_df, order=suggestions_df['Suggestions'].value_counts().index)\n",
    "    plt.title('Autocomplete Suggestions Distribution')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Suggestions')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No autocomplete suggestions found for the prefix '{prefix}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No autocomplete suggestions found for the prefix 'exam'.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg') # or 'Qt5Agg' if you have PyQt5 installed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize autocomplete suggestions\n",
    "if predictions: # Check if there are predictions to display\n",
    "    suggestions_df = pd.DataFrame({'Suggestions': predictions})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(y='Suggestions', data=suggestions_df, order=suggestions_df['Suggestions'].value_counts().index)\n",
    "    plt.title('Autocomplete Suggestions Distribution')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Suggestions')\n",
    "    plt.savefig('autocomplete_suggestions.png') # Save the plot as a PNG file\n",
    "    plt.close() # Close the figure to free up memory\n",
    "    print(\"Plot saved as 'autocomplete_suggestions.png'\")\n",
    "else:\n",
    "    print(f\"No autocomplete suggestions found for the prefix '{prefix}'.\")\n",
    "\n",
    "# Visualize autocomplete suggestions\n",
    "suggestions_df = pd.DataFrame({'Suggestions': predictions})\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y='Suggestions', data=suggestions_df, order=suggestions_df['Suggestions'].value_counts().index)\n",
    "plt.title('Autocomplete Suggestions Distribution')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Suggestions')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Input: Hello! This is a test with numbers 123 and special chars @#$\n",
      "Cleaned Input: Hello This is a test with numbers 123 and special chars \n"
     ]
    }
   ],
   "source": [
    "def clean_input(text):\n",
    "    # Remove special characters and handle numbers\n",
    "    cleaned_text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "    return cleaned_text\n",
    "\n",
    "# Example usage\n",
    "user_input = \"Hello! This is a test with numbers 123 and special chars @#$\"\n",
    "cleaned_user_input = clean_input(user_input)\n",
    "\n",
    "print(\"Original Input:\", user_input)\n",
    "print(\"Cleaned Input:\", cleaned_user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('creditcard.csv') # Adjust the path as needed\n",
    "\n",
    "# Tokenize the words in the 'V1' column\n",
    "# Convert to string and drop NaN values\n",
    "word_list = ' '.join(data['V1'].dropna().astype(str).tolist()).split()\n",
    "word_freq = Counter(word_list)\n",
    "\n",
    "# Get the most common words\n",
    "common_words = word_freq.most_common(20)\n",
    "words, frequencies = zip(*common_words)\n",
    "\n",
    "# Plotting the word frequency distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=list(frequencies), y=list(words), hue=list(words), palette='viridis')\n",
    "plt.title('Top 20 Most Common Words')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = ['example', 'sample', 'examine', 'exempt', 'exercise']\n",
    "suggestion_counts = [150, 80, 30, 20, 10] # Example counts\n",
    "\n",
    "# Plotting suggestion clicks\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=suggestions, y=suggestion_counts, hue=suggestions, palette='coolwarm')\n",
    "plt.title('Autocomplete Suggestions Click Count')\n",
    "plt.xlabel('Suggestions')\n",
    "plt.ylabel('Click Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example true labels and predicted labels (replace with your actual data)\n",
    "y_true = [0, 1, 0, 1, 0, 1, 0] # Replace with actual true labels\n",
    "y_pred = [0, 1, 1, 1, 0, 0, 1] # Replace with your predictions\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated accuracy over epochs (replace with actual data)\n",
    "epochs = list(range(1, 11))\n",
    "accuracy = [0.6, 0.65, 0.7, 0.75, 0.8, 0.82, 0.85, 0.87, 0.9, 0.95]\n",
    "\n",
    "# Plotting the accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, accuracy, marker='o', linestyle='-', color='b')\n",
    "plt.title('Model Accuracy Over Time')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(epochs)\n",
    "plt.grid()\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example feedback counts (positive vs negative)\n",
    "feedback_labels = ['Positive', 'Negative']\n",
    "feedback_counts = [80, 20] # Example counts\n",
    "\n",
    "# Plotting user feedback\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=feedback_labels, y=feedback_counts, hue=feedback_labels, palette='pastel')\n",
    "plt.title('User Feedback on Suggestions')\n",
    "plt.xlabel('Feedback Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Wordcloud in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Wordcloud) (10.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Wordcloud) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->Wordcloud) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->Wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->Wordcloud) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->Wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->Wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->Wordcloud) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->Wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->Wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: pip in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (25.1.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Join all the words together\n",
    "all_words = ' '.join(data['V1'].dropna().astype(str).tolist())\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='black', colormap='rainbow').generate(all_words)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('creditcard.csv') # Adjust the path as needed\n",
    "\n",
    "# Ensure the 'V1' column is treated as text, and drop NaN values\n",
    "data['V1'] = data['V1'].astype(str)\n",
    "data = data.dropna(subset=['V1'])\n",
    "\n",
    "# Tokenize the words in the 'V1' column\n",
    "word_list = ' '.join(data['V1'].tolist()).split()\n",
    "word_freq = Counter(word_list)\n",
    "\n",
    "# Get the frequencies of the top 10 words\n",
    "common_words = word_freq.most_common(10)\n",
    "words, frequencies = zip(*common_words)\n",
    "\n",
    "# Create radial bar chart\n",
    "angles = np.linspace(0, 2 * np.pi, len(frequencies), endpoint=False).tolist()\n",
    "frequencies = list(frequencies) + [frequencies[0]]# Complete the loop\n",
    "angles += angles[:1] # Ensure loop closure\n",
    "\n",
    "# Plot the radial bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'projection': 'polar'})\n",
    "ax.fill(angles, frequencies, color='purple', alpha=0.25)\n",
    "ax.plot(angles, frequencies, color='purple', linewidth=2, linestyle='solid')\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(words)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('creditcard.csv') # Adjust the path as needed\n",
    "\n",
    "# Violin plot for 'Amount' vs 'Class'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='Class', y='Amount', data=data, hue='Class', palette='Set2')\n",
    "plt.title('Violin Plot for Amount vs Class')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('creditcard.csv') # Adjust the path as needed\n",
    "\n",
    "# Assuming 'V2', 'V3', 'V4', and 'Class' are columns in the dataset\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create 3D scatter plot\n",
    "scatter = ax.scatter(data['V2'], data['V3'], data['V4'], c=data['Class'], cmap='coolwarm', s=10, alpha=0.7)\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('V2')\n",
    "ax.set_ylabel('V3')\n",
    "ax.set_zlabel('V4')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Class')\n",
    "\n",
    "# Show plot\n",
    "plt.title('3D Scatter Plot of V2, V3, V4 colored by Class')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have numerical columns 'V2' and 'V3'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hexbin(data['V2'], data['V3'], gridsize=30, cmap='inferno')\n",
    "plt.colorbar(label='density')\n",
    "plt.title('Hexbin Plot for V2 and V3')\n",
    "plt.xlabel('V2')\n",
    "plt.ylabel('V3')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you're visualizing correlations (adjust for your data structure)\n",
    "corr = data.corr()\n",
    "\n",
    "# Adding random noise\n",
    "noise = np.random.normal(0, 0.1, corr.shape)\n",
    "noisy_corr = corr + noise\n",
    "\n",
    "# Create a mask to show only the lower triangle (to reduce clutter)\n",
    "mask = np.triu(np.ones_like(noisy_corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Draw the heatmap with the mask\n",
    "sns.heatmap(noisy_corr, mask=mask, cmap='coolwarm', center=0, annot=False, linewidths=0.5)\n",
    "\n",
    "# Add title\n",
    "plt.title('Noisy Heatmap of Correlations (Lower Triangle)', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
